# ğŸš€ Guide de Fine-Tuning - DÃ©marrage Rapide

## âœ… Scripts CrÃ©Ã©s

Tous les scripts nÃ©cessaires sont prÃªts :

1. âœ… `prepare_instruction_data.py` - TÃ©lÃ©charge et formate les datasets
2. âœ… `finetune.py` - Script de fine-tuning optimisÃ©
3. âœ… `compare_models.py` - Compare avant/aprÃ¨s
4. âœ… `launch_finetune_6gpu.sh` - Lance sur 6 GPUs (Option 2)
5. âœ… `test_finetune_1gpu.sh` - Test rapide sur 1 GPU

---

## ğŸ¯ Option 2 - Grande CapacitÃ© (RecommandÃ©)

### Configuration
- **6x RTX 4090** (144 GB VRAM total)
- **Batch size effectif**: 192 (4 Ã— 6 GPUs Ã— 8 accumulation)
- **Learning rate**: 5e-6 (trÃ¨s bas pour prÃ©server le modÃ¨le)
- **Steps**: 25,000 (~20h d'entraÃ®nement)
- **Datasets**: Alpaca + Dolly + OpenAssistant (~200k exemples)

---

## ğŸ“‹ Ã‰tapes RecommandÃ©es

### **Ã‰tape 1 : Test Rapide (RECOMMANDÃ‰)** âš¡

Toujours tester avant de lancer un long training !

```bash
# Test de 15 minutes sur 1 GPU pour valider que tout fonctionne
./test_finetune_1gpu.sh
```

**VÃ©rifications** :
- âœ… La loss diminue-t-elle ?
- âœ… Pas d'erreur OOM (Out of Memory) ?
- âœ… Les checkpoints se sauvegardent ?
- âœ… Le modÃ¨le gÃ©nÃ¨re mieux qu'avant ?

**Test du checkpoint** :
```bash
python demo_chat.py --checkpoint checkpoints/test_finetune/checkpoint_step_500.pt
```

---

### **Ã‰tape 2 : Fine-Tuning Complet** ğŸ”¥

Si le test fonctionne, lance le vrai fine-tuning :

```bash
# ~20h d'entraÃ®nement sur 6 GPUs
./launch_finetune_6gpu.sh
```

**Monitoring pendant le training** :
```bash
# Dans un autre terminal
tail -f logs/finetune/*.log

# VÃ©rifier l'utilisation GPU
watch -n 1 nvidia-smi
```

**Points de contrÃ´le** :
- **@1000 steps (~1h)** : Loss doit avoir baissÃ© de 30-40%
- **@5000 steps (~4h)** : Tester avec demo_chat.py
- **@10000 steps (~8h)** : Comparer avec modÃ¨le de base
- **@15000 steps (~12h)** : VÃ©rifier que loss continue de descendre
- **@25000 steps (~20h)** : Fin du training

---

### **Ã‰tape 3 : Ã‰valuation** ğŸ“Š

```bash
# Comparer base vs fine-tunÃ©
python compare_models.py \
    --base_model checkpoints/model_gpu5/final_model.pt \
    --finetuned_model checkpoints/finetuned/finetuned_model.pt

# Tester le modÃ¨le final
python demo_chat.py --checkpoint checkpoints/finetuned/finetuned_model.pt
```

---

## ğŸ›ï¸ ParamÃ¨tres Personnalisables

Si tu veux ajuster :

### Plus Rapide (mais moins de qualitÃ©)
```bash
# 10k steps au lieu de 25k (~8h au lieu de 20h)
torchrun --nproc_per_node=6 finetune.py \
    --max_steps 10000 \
    --learning_rate 1e-5 \
    [autres params...]
```

### Plus Conservateur (moins de risque d'oublier)
```bash
# Learning rate encore plus bas
torchrun --nproc_per_node=6 finetune.py \
    --learning_rate 2e-6 \
    --max_steps 30000 \
    [autres params...]
```

### Plus de CapacitÃ© (si tu as >6 GPUs)
```bash
# Exemple pour 8 GPUs
torchrun --nproc_per_node=8 finetune.py \
    --batch_size 6 \
    --gradient_accumulation_steps 6 \
    [autres params...]
# Batch effectif = 6 Ã— 8 Ã— 6 = 288
```

---

## ğŸ”§ DÃ©pannage

### Erreur OOM (Out of Memory)
```bash
# RÃ©duire batch size
--batch_size 2  # au lieu de 4

# Ou rÃ©duire max_length
--max_length 512  # au lieu de 1024
```

### Loss qui augmente
```bash
# Learning rate trop Ã©levÃ©, rÃ©duire de moitiÃ©
--learning_rate 2.5e-6  # au lieu de 5e-6
```

### Training trop lent
```bash
# VÃ©rifier que tous les GPUs sont utilisÃ©s
nvidia-smi

# Augmenter num_workers
--num_workers 8  # au lieu de 4
```

### Datasets ne se tÃ©lÃ©chargent pas
```bash
# Si problÃ¨me HuggingFace, utiliser seulement Alpaca
python prepare_instruction_data.py --max_samples 52000
# Force l'utilisation d'Alpaca seulement (plus fiable)
```

---

## ğŸ“Š RÃ©sultats Attendus

### Avant Fine-Tuning âŒ
```
Q: What is the capital of France?
A: What are the major areas of the country? [incohÃ©rent]

Q: What is 2+2?
A: The first is the number of words... [hors-sujet]
```

### AprÃ¨s Fine-Tuning âœ…
```
Q: What is the capital of France?
A: The capital of France is Paris.

Q: What is 2+2?
A: 2+2 equals 4.
```

**MÃ©triques de succÃ¨s** :
- âœ… RÃ©pond correctement aux questions factuelles
- âœ… Suit les instructions (ex: "Write a haiku")
- âœ… Maintient le contexte conversationnel
- âœ… Moins d'hallucinations
- âœ… Code gÃ©nÃ©rÃ© cohÃ©rent

---

## â±ï¸ Timeline ComplÃ¨te

| Temps | Action |
|-------|--------|
| **T+0** | Lancer `test_finetune_1gpu.sh` |
| **T+15min** | VÃ©rifier rÃ©sultats du test |
| **T+30min** | Si OK, lancer `launch_finetune_6gpu.sh` |
| **T+1h** | Checkpoint @1000 steps - vÃ©rifier loss |
| **T+4h** | Checkpoint @5000 steps - tester qualitÃ© |
| **T+8h** | Checkpoint @10000 steps - comparer |
| **T+12h** | Checkpoint @15000 steps - validation |
| **T+16h** | Checkpoint @20000 steps - presque fini |
| **T+20h** | Checkpoint @25000 steps - **TERMINÃ‰** |
| **T+20h30** | Ã‰valuation finale et comparaison |

---

## ğŸ¯ Commandes Essentielles

### PrÃ©paration
```bash
# 1. PrÃ©parer les donnÃ©es (si pas dÃ©jÃ  fait)
python prepare_instruction_data.py

# 2. Test rapide (OBLIGATOIRE)
./test_finetune_1gpu.sh
```

### Fine-Tuning
```bash
# 3. Lancer le vrai fine-tuning
./launch_finetune_6gpu.sh

# Ou manuellement avec contrÃ´le total
torchrun --nproc_per_node=6 finetune.py \
    --train_file data/instruction/train.jsonl \
    --checkpoint checkpoints/model_gpu5/final_model.pt \
    --max_steps 25000 \
    --batch_size 4 \
    --learning_rate 5e-6
```

### Ã‰valuation
```bash
# 4. Tester pendant l'entraÃ®nement
python demo_chat.py --checkpoint checkpoints/finetuned/checkpoint_step_5000.pt

# 5. Comparer final
python compare_models.py
```

---

## ğŸ’¡ Conseils Pratiques

1. **Toujours faire le test 1 GPU d'abord** - Ã‰conomise du temps si config incorrecte
2. **Monitorer la loss** - Doit descendre graduellement, pas de spike
3. **Tester aux checkpoints** - QualitÃ© observable dÃ¨s 5000 steps
4. **Garder 3-5 checkpoints** - Au cas oÃ¹ overfitting vers la fin
5. **Patience** - 20h c'est long, mais Ã§a vaut le coup !

---

## ğŸš¨ Erreurs Ã  Ã‰viter

1. âŒ **Ne pas tester avant** â†’ Risque de perdre 20h si erreur config
2. âŒ **Learning rate trop haut** â†’ Catastrophic forgetting
3. âŒ **Pas de monitoring** â†’ Impossible de dÃ©tecter les problÃ¨mes
4. âŒ **Attendre 25k steps sans vÃ©rifier** â†’ Peut overfitter
5. âŒ **Oublier de sauvegarder les checkpoints** â†’ Perdu si crash

---

## âœ… Checklist Avant de Lancer

- [ ] Test 1 GPU rÃ©ussi (`test_finetune_1gpu.sh`)
- [ ] Datasets tÃ©lÃ©chargÃ©s (`data/instruction/train.jsonl` existe)
- [ ] Checkpoint de base existe (`checkpoints/model_gpu5/final_model.pt`)
- [ ] Espace disque suffisant (50GB minimum)
- [ ] Toutes les 6 GPUs disponibles (`nvidia-smi`)
- [ ] Temps disponible (~24h sans interruption recommandÃ©)

---

## ğŸ‰ PrÃªt Ã  Commencer ?

```bash
# GO GO GO ! ğŸš€
./test_finetune_1gpu.sh
```

**Good luck! ğŸ’ª**

