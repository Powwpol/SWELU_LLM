# ğŸš€ Instructions de Configuration - EntraÃ®nement Multi-GPU

## âš ï¸ ProblÃ¨me Actuel: Rate Limit HuggingFace

L'entraÃ®nement a Ã©tÃ© bloquÃ© par un **rate limit HuggingFace**. SlimPajama-627B nÃ©cessite un token HF pour Ãªtre tÃ©lÃ©chargÃ©.

```
Error: 429 Client Error: Too Many Requests
Solution: CrÃ©er/utiliser un token HuggingFace
```

---

## ğŸ”§ Solution Rapide

### Option 1: CrÃ©er un Token HuggingFace (RECOMMANDÃ‰)

1. **CrÃ©er un compte HF** (si pas encore fait):
   - Aller sur: https://huggingface.co/join
   - S'inscrire gratuitement

2. **GÃ©nÃ©rer un token**:
   - Aller sur: https://huggingface.co/settings/tokens
   - Cliquer "New token"
   - Nom: "swelu-training"
   - Type: "Read"
   - Copier le token

3. **Configurer le token**:
   ```bash
   # MÃ©thode 1: Export direct
   export HF_TOKEN=hf_votre_token_ici
   
   # MÃ©thode 2: Via script interactif
   ./setup_hf_token.sh
   
   # MÃ©thode 3: CrÃ©er .env manuellement
   echo "HF_TOKEN=hf_votre_token_ici" > .env
   ```

4. **Lancer l'entraÃ®nement**:
   ```bash
   ./launch_multi_gpu_with_token.sh
   ```

---

### Option 2: Login HuggingFace CLI

```bash
# Installer huggingface-cli si nÃ©cessaire
pip install huggingface-hub

# Login interactif
huggingface-cli login

# Puis lancer l'entraÃ®nement
./launch_multi_gpu_with_token.sh
```

---

### Option 3: Utiliser un Dataset Alternatif (TEMPORAIRE)

Si vous ne pouvez pas obtenir un token HF immÃ©diatement, utilisez Wikipedia Ã  la place:

```bash
# Modifier le script pour utiliser wikipedia
python src/train.py \
  --dataset wikipedia \
  --max_steps 757500 \
  [... autres params ...]
```

**Note:** Wikipedia est beaucoup plus petit (~20GB) que SlimPajama (627B tokens), donc moins optimal.

---

## ğŸ“Š Configuration Multi-GPU

Une fois le token configurÃ©, l'entraÃ®nement utilisera **6x RTX 4090** en parallÃ¨le:

### Avantages:
- **Speedup:** ~6x plus rapide
- **DurÃ©e:** ~11.7h au lieu de 70h
- **Ã‰conomie:** ~58h de temps GPU
- **Tokens:** 12.4B (ratio optimal 100x)

### RÃ©partition:
```
GPU 0: Process rank 0 (master)
GPU 1: Process rank 1
GPU 2: Process rank 2
GPU 3: Process rank 3
GPU 4: Process rank 4
GPU 5: Process rank 5
```

---

## âœ… VÃ©rification Post-Lancement

AprÃ¨s avoir lancÃ© l'entraÃ®nement, vÃ©rifiez que les 6 GPUs sont utilisÃ©s:

```bash
# VÃ©rifier les GPUs
nvidia-smi

# Devrait montrer:
# - 6 processus Python
# - ~885MB par GPU
# - Utilisation >80% sur chaque GPU

# Suivre les logs
tail -f training.log

# Monitoring continu
watch -n 5 './monitor_training.sh'
```

---

## ğŸ› Troubleshooting

### ProblÃ¨me: "Rate limit"
- **Solution:** Configurer HF_TOKEN (voir Option 1 ci-dessus)

### ProblÃ¨me: "All processes on GPU 0"
- **Solution:** DÃ©jÃ  corrigÃ© avec `CUDA_VISIBLE_DEVICES=0,1,2,3,4,5`

### ProblÃ¨me: "OOM (Out of Memory)"
- **Solution:** RÃ©duire batch_size Ã  2 ou 3

### ProblÃ¨me: "Connection timeout"
- **Solution:** VÃ©rifier connexion internet, SlimPajama est volumineux

---

## ğŸ“ Commandes Utiles

```bash
# Configuration initiale
./setup_hf_token.sh                    # Configurer token HF

# Lancement
./launch_multi_gpu_with_token.sh       # Multi-GPU (6x RTX 4090)
./launch_llama_style.sh                # Single GPU (plus lent)

# Monitoring
./monitor_training.sh                  # Status rapide
tail -f training.log                   # Logs en direct
watch -n 10 nvidia-smi                 # GPUs en temps rÃ©el

# ContrÃ´le
pkill -f train.py                      # ArrÃªter entraÃ®nement
ps aux | grep train                    # VÃ©rifier processus

# Checkpoints
ls -lh checkpoints/                    # Voir checkpoints sauvegardÃ©s
```

---

## ğŸ¯ Prochaines Ã‰tapes

1. âœ… Obtenir un token HuggingFace
2. âœ… Configurer le token (`.env` ou `export`)
3. ğŸš€ Lancer `./launch_multi_gpu_with_token.sh`
4. ğŸ“Š Monitorer avec `watch -n 10 ./monitor_training.sh`
5. â³ Attendre ~11.7h
6. ğŸ‰ ModÃ¨le final dans `checkpoints/final_model.pt`

---

## ğŸ’¡ Notes Importantes

- Le premier lancement tÃ©lÃ©charge les mÃ©tadonnÃ©es SlimPajama (~5min)
- Les checkpoints sont sauvegardÃ©s tous les 5,000 steps
- Utilisation de ~885MB par GPU
- Total mÃ©moire: ~5.3GB sur les 6 GPUs
- Bande passante: Important pour streaming SlimPajama

---

**Pour toute question, vÃ©rifiez les logs: `tail -f training.log`**

