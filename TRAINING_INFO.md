# ğŸš€ EntraÃ®nement MambaSWELU - Configuration Actuelle

## ğŸ“Š Configuration Optimale (LLaMA Style)

**DÃ©marrÃ© le:** `date`

### ModÃ¨le
- **Architecture:** MambaSWELU
- **ParamÃ¨tres:** 124,104,719 (~124M)
- **Couches:** 6 Mamba blocks + 3 Dense layers
- **Dimension:** 1024
- **Activation:** SWELU (learnable)

### Dataset
- **Source:** SlimPajama-627B
- **Mode:** Streaming (pas de tÃ©lÃ©chargement complet)
- **Tokenizer:** GPT-2 (vocab_size=50,257)

### HyperparamÃ¨tres
```bash
batch_size:                  4
gradient_accumulation_steps: 4
effective_batch_size:        16
sequence_length:             1024
max_steps:                   757,500
learning_rate:               3e-4
weight_decay:                0.1
warmup_steps:                2,000
mixed_precision:             BF16
```

### Tokens d'EntraÃ®nement
- **Tokens par step:** 16,384
- **Total tokens:** 12,410,471,900 (12.4B)
- **Ratio tokens/param:** 100x (LLaMA style - optimal)
- **Utilisation SlimPajama:** ~2% du dataset

### DurÃ©e EstimÃ©e
- **Total:** ~70 heures (~3 jours)
- **Par checkpoint (5k steps):** ~28 minutes
- **Nombre de checkpoints:** 151

### Checkpoints
- **FrÃ©quence:** Tous les 5,000 steps
- **Localisation:** `./checkpoints/`
- **Format:** `model_step_XXXXX.pt`
- **Contenu:** 
  - Ã‰tat du modÃ¨le
  - Ã‰tat de l'optimiseur
  - Global step
  - Epoch

### Monitoring

**Commandes utiles:**
```bash
# Suivre les logs en temps rÃ©el
tail -f training.log

# Monitoring rapide
./monitor_training.sh

# Auto-refresh toutes les 10 secondes
watch -n 10 ./monitor_training.sh

# VÃ©rifier GPU
nvidia-smi -l 5

# ArrÃªter l'entraÃ®nement
pkill -f train.py
```

**MÃ©triques Ã  surveiller:**
- Loss: devrait diminuer progressivement
- Learning rate: warmup puis cosine decay
- GPU utilization: devrait Ãªtre >80%
- Memory: ~885MB sur RTX 4090

### Reprendre l'EntraÃ®nement

Si l'entraÃ®nement s'arrÃªte, reprendre depuis le dernier checkpoint:

```bash
# Trouver le dernier checkpoint
ls -lt checkpoints/*.pt | head -1

# Relancer avec reprise
python src/train.py \
  --dataset slimpajama \
  --resume_from_checkpoint ./checkpoints/model_step_XXXXX.pt \
  [... autres paramÃ¨tres identiques ...]
```

### Lois d'Ã‰chelle RespectÃ©es

âœ… **Chinchilla (minimum):** 20 tokens/param â†’ 2.48B tokens  
âœ… **LLaMA (optimal):** 100 tokens/param â†’ 12.4B tokens â† **Configuration actuelle**  
âœ… **GPT-3 (rÃ©fÃ©rence):** 300 tokens/param â†’ 37.2B tokens

Notre configuration suit les meilleures pratiques modernes (LLaMA/Pythia).

### Notes Importantes

1. **Premier dÃ©marrage:** TÃ©lÃ©chargement des mÃ©tadonnÃ©es SlimPajama (~5 min)
2. **Validation:** DÃ©sactivÃ©e en mode streaming (pas critique)
3. **Mamba-SSM:** Utilise version simplifiÃ©e (installer `mamba-ssm` pour optimisation)
4. **WandB:** DÃ©sactivÃ© (activer avec `--use_wandb` si installÃ©)

### Fichiers GÃ©nÃ©rÃ©s

```
/root/SWELU_LLM/
â”œâ”€â”€ training.log                    # Logs d'entraÃ®nement
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ model_step_5000.pt
â”‚   â”œâ”€â”€ model_step_10000.pt
â”‚   â””â”€â”€ ... (151 checkpoints au total)
â”‚   â””â”€â”€ final_model.pt             # ModÃ¨le final
â””â”€â”€ training_old_*.log             # Backups des anciens logs
```

### Prochaines Ã‰tapes AprÃ¨s EntraÃ®nement

1. **Ã‰valuation:** Tester la perplexitÃ© sur un validation set
2. **GÃ©nÃ©ration:** Utiliser `src/inference.py` pour gÃ©nÃ©rer du texte
3. **Fine-tuning:** Adapter sur des tÃ¢ches spÃ©cifiques si besoin
4. **Comparaison:** Benchmarker vs modÃ¨les de taille similaire

---

**Pour plus d'infos:** Consulter `configs/optimal_training.sh` pour d'autres configurations.

