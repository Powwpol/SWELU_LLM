# ğŸš€ DÃ‰MARRAGE FINE-TUNING - Option 2 Grande CapacitÃ©

## âœ… INFRASTRUCTURE PRÃŠTE

Tous les scripts sont crÃ©Ã©s et opÃ©rationnels :

```
âœ… prepare_instruction_data.py  (11 KB)  - TÃ©lÃ©charge datasets
âœ… finetune.py                   (16 KB)  - Fine-tuning multi-GPU  
âœ… compare_models.py             (6 KB)   - Compare avant/aprÃ¨s
âœ… launch_finetune_6gpu.sh       (4 KB)   - Lance 6 GPUs
âœ… test_finetune_1gpu.sh         (3 KB)   - Test rapide 1 GPU
```

---

## ğŸ¯ CONFIGURATION OPTION 2

**Objectif** : Fine-tuning conversationnel de haute qualitÃ©

| ParamÃ¨tre | Valeur | Justification |
|-----------|--------|---------------|
| **GPUs** | 6x RTX 4090 | Maximum de capacitÃ© |
| **Batch effectif** | 192 | 4 Ã— 6 Ã— 8 accumulation |
| **Learning rate** | 5e-6 | TrÃ¨s bas (prÃ©serve modÃ¨le base) |
| **Steps** | 25,000 | ~200k exemples vus |
| **DurÃ©e** | ~20h | Sur 6 GPUs |
| **Datasets** | Alpaca + Dolly + OA | ~200-250k exemples |

---

## ğŸƒ DÃ‰MARRAGE IMMÃ‰DIAT

### Option A : Test Rapide Puis Full (RECOMMANDÃ‰) âœ…

```bash
# 1. Test de 15 minutes sur 1 GPU
./test_finetune_1gpu.sh

# 2. Si OK, lancer le vrai fine-tuning
./launch_finetune_6gpu.sh
```

### Option B : Direct Full Training (Si Confiant) ğŸ”¥

```bash
# Tout en un - lance directement les 6 GPUs
./launch_finetune_6gpu.sh
```

---

## ğŸ“Š MONITORING

### Pendant l'entraÃ®nement

```bash
# Terminal 1 : Suivre les logs
tail -f logs/finetune/*.log

# Terminal 2 : Surveiller GPUs  
watch -n 1 nvidia-smi

# Terminal 3 : Tester aux checkpoints
python demo_chat.py --checkpoint checkpoints/finetuned/checkpoint_step_5000.pt
```

### Checkpoints clÃ©s

| Step | Temps | Action |
|------|-------|--------|
| 1,000 | ~1h | VÃ©rifier loss baisse |
| 5,000 | ~4h | **Premier test qualitÃ©** |
| 10,000 | ~8h | Comparer vs base |
| 15,000 | ~12h | Validation continue |
| 20,000 | ~16h | Presque fini |
| 25,000 | ~20h | **TERMINÃ‰** |

---

## ğŸ¯ RÃ‰SULTATS ATTENDUS

### Avant Fine-Tuning âŒ

```
Prompt: What is the capital of France?
Base:   What are the major areas of the country? [INCOHÃ‰RENT]

Prompt: User: Hello! How are you?
Base:   J.P. Williams. It was a great time... [HORS-SUJET]
```

### AprÃ¨s Fine-Tuning âœ…

```
Prompt: What is the capital of France?
Finetuned: The capital of France is Paris.

Prompt: User: Hello! How are you?
Finetuned: Hello! I'm doing well, thank you for asking. How can I help you today?
```

---

## ğŸš¨ POINTS D'ATTENTION

### Critiques Ã  Surveiller

1. **Loss qui augmente** â†’ Learning rate trop haut
   - Solution : RÃ©duire Ã  2.5e-6 et relancer

2. **OOM (Out of Memory)** â†’ Batch trop grand
   - Solution : `--batch_size 2` au lieu de 4

3. **Loss qui stagne** â†’ Peut-Ãªtre dÃ©jÃ  optimal
   - Solution : Tester qualitÃ©, possiblement arrÃªter

4. **GÃ©nÃ©ration bizarre** â†’ Catastrophic forgetting
   - Solution : Utiliser checkpoint prÃ©cÃ©dent, LR trop haut

---

## ğŸ’¡ ASTUCES PRO

1. **Tester dÃ¨s 5000 steps** - QualitÃ© observable rapidement
2. **Garder 5 checkpoints** - Au cas oÃ¹ overfitting
3. **Comparer rÃ©guliÃ¨rement** - Base vs FinetunÃ©
4. **Patience** - 20h c'est long mais Ã§a vaut le coup !

---

## âœ… CHECKLIST FINALE

Avant de lancer, vÃ©rifie :

- [ ] 6x GPUs disponibles (`nvidia-smi`)
- [ ] ~50GB espace disque libre
- [ ] Checkpoint base existe (`checkpoints/model_gpu5/final_model.pt`)
- [ ] Scripts exÃ©cutables (`chmod +x *.sh`)
- [ ] Test 1 GPU rÃ©ussi (si option A)

---

## ğŸ¬ COMMANDE FINALE

```bash
# OPTION RECOMMANDÃ‰E
./test_finetune_1gpu.sh          # 15 min de test
# puis si OK :
./launch_finetune_6gpu.sh        # 20h de fine-tuning

# OU DIRECT
./launch_finetune_6gpu.sh        # YOLO ğŸš€
```

---

## ğŸ“š DOCUMENTATION

- `FINETUNE_QUICKSTART.md` - Guide dÃ©taillÃ©
- `FINE_TUNING_STRATEGY.md` - StratÃ©gie complÃ¨te
- `finetune.py --help` - Toutes les options

---

## ğŸ†˜ BESOIN D'AIDE ?

Si problÃ¨me, vÃ©rifie :

1. Logs : `logs/finetune/*.log`
2. GPU memory : `nvidia-smi`
3. Datasets : `ls data/instruction/`
4. Checkpoints : `ls checkpoints/finetuned/`

---

## ğŸ”¥ READY TO GO ?

```bash
cd /root/SWELU_LLM
./test_finetune_1gpu.sh
```

**Let's make this model GREAT! ğŸ’ªğŸš€**

